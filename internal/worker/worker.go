package worker

import (
	"bufio"
	"context"
	"fmt"
	"log"
	"os"
	"os/exec"
	"path/filepath"
	"strconv"
	"strings"
	"sync"
	"syscall"
	"time"

	"github.com/stm/video-transcoder/internal/config"
	"github.com/stm/video-transcoder/internal/database"
	"github.com/stm/video-transcoder/internal/metrics"
)

// Worker è½¬ç å·¥ä½œå™¨
type Worker struct {
	config         *config.Config
	db             *database.DB
	forceRun       bool // å¼ºåˆ¶è¿è¡Œæ ‡å¿—
	maxWorkers     int  // åŠ¨æ€æœ€å¤§Workeræ•°ï¼ˆå¯åœ¨è¿è¡Œæ—¶è°ƒæ•´ï¼‰
	taskQueue      chan *database.Task
	workerCount    int
	wg             sync.WaitGroup
	mu             sync.RWMutex // ä¿æŠ¤ forceRun, maxWorkers å’Œ workerCount
	workerCtx      context.Context
	cancelWorkers  context.CancelFunc
	workersStopped bool
	mainCtx        context.Context // ä¸» contextï¼Œç”¨äºå¯åŠ¨ Worker
}

// New åˆ›å»ºWorkerå®ä¾‹
func New(cfg *config.Config, db *database.DB) *Worker {
	return &Worker{
		config:         cfg,
		db:             db,
		maxWorkers:     cfg.System.MaxWorkers, // ä»é…ç½®åˆå§‹åŒ–
		taskQueue:      make(chan *database.Task, cfg.System.TaskQueueSize),
		workerCount:    0,
		workersStopped: true,
	}
}

// Run è¿è¡ŒWorkerå®ˆæŠ¤è¿›ç¨‹
func (w *Worker) Run(ctx context.Context) {
	log.Println("[Worker] Workerå®ˆæŠ¤è¿›ç¨‹å¯åŠ¨")

	// ä¿å­˜ä¸» context
	w.mainCtx = ctx

	// å¯åŠ¨ä»»åŠ¡è°ƒåº¦å™¨
	go w.scheduler(ctx)

	// å¯åŠ¨Worker Pool
	go w.manageWorkerPool(ctx)

	<-ctx.Done()
	log.Println("[Worker] æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œç­‰å¾…Workerå®Œæˆ...")

	// å…³é—­ä»»åŠ¡é˜Ÿåˆ—
	close(w.taskQueue)

	// ç­‰å¾…æ‰€æœ‰Workerå®Œæˆ
	w.wg.Wait()
	log.Println("[Worker] Workerå®ˆæŠ¤è¿›ç¨‹å·²é€€å‡º")
}

// isWorkingHours æ£€æŸ¥æ˜¯å¦åœ¨å·¥ä½œæ—¶é—´çª—å£å†…
func (w *Worker) IsWorkingHours() bool {
	now := time.Now()
	hour := now.Hour()

	start := w.config.System.CronStart
	end := w.config.System.CronEnd

	// å¤„ç†è·¨å¤©æƒ…å†µï¼ˆå¦‚ 22:00 - 06:00ï¼‰
	if start < end {
		return hour >= start && hour < end
	} else {
		return hour >= start || hour < end
	}
}

// GetForceRun è·å–å¼ºåˆ¶è¿è¡ŒçŠ¶æ€
func (w *Worker) GetForceRun() bool {
	w.mu.RLock()
	defer w.mu.RUnlock()
	return w.forceRun
}

// SetForceRun è®¾ç½®å¼ºåˆ¶è¿è¡Œæ ‡å¿—
func (w *Worker) SetForceRun(force bool) {
	w.mu.Lock()
	w.forceRun = force
	w.mu.Unlock()

	if force {
		log.Println("[Worker] å¼ºåˆ¶è¿è¡Œæ¨¡å¼å·²å¯ç”¨")
		// ç«‹å³è§¦å‘ Worker Pool è°ƒæ•´
		go func() {
			targetWorkers := w.getTargetWorkerCount()
			currentWorkers := w.GetWorkerCount()

			if targetWorkers != currentWorkers {
				log.Printf("[WorkerPool] å¼ºåˆ¶æ¨¡å¼è§¦å‘ï¼šè°ƒæ•´Workeræ•°é‡ %d -> %d", currentWorkers, targetWorkers)
				// ä½¿ç”¨ä¸» context
				if w.mainCtx != nil {
					w.adjustWorkerPool(w.mainCtx, targetWorkers)
				}
			}
		}()
	} else {
		log.Println("[Worker] å¼ºåˆ¶è¿è¡Œæ¨¡å¼å·²å…³é—­")
		// ç«‹å³æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢ Worker
		go func() {
			targetWorkers := w.getTargetWorkerCount()
			currentWorkers := w.GetWorkerCount()

			if targetWorkers != currentWorkers {
				log.Printf("[WorkerPool] å–æ¶ˆå¼ºåˆ¶æ¨¡å¼ï¼šè°ƒæ•´Workeræ•°é‡ %d -> %d", currentWorkers, targetWorkers)
				if w.mainCtx != nil {
					w.adjustWorkerPool(w.mainCtx, targetWorkers)
				}
			}
		}()
	}
}

// GetWorkerCount è·å–å½“å‰Workeræ•°é‡
func (w *Worker) GetWorkerCount() int {
	w.mu.RLock()
	defer w.mu.RUnlock()
	return w.workerCount
}

// GetMaxWorkers è·å–æœ€å¤§Workeræ•°é‡
func (w *Worker) GetMaxWorkers() int {
	w.mu.RLock()
	defer w.mu.RUnlock()
	return w.maxWorkers
}

// SetMaxWorkers è®¾ç½®æœ€å¤§Workeræ•°é‡ï¼ˆè¿è¡Œæ—¶åŠ¨æ€è°ƒæ•´ï¼‰
func (w *Worker) SetMaxWorkers(count int) {
	w.mu.Lock()
	defer w.mu.Unlock()

	if count < 1 {
		count = 1
	}
	if count > 10 {
		count = 10 // å®‰å…¨ä¸Šé™
	}

	w.maxWorkers = count
	log.Printf("[Worker] æœ€å¤§Workeræ•°é‡å·²è°ƒæ•´ä¸º: %d", count)
}

// scheduler ä»»åŠ¡è°ƒåº¦å™¨ï¼Œå®šæœŸä»æ•°æ®åº“è·å–ä»»åŠ¡
func (w *Worker) scheduler(ctx context.Context) {
	interval := time.Duration(w.config.System.SchedulerInterval) * time.Second
	ticker := time.NewTicker(interval)
	defer ticker.Stop()

	log.Printf("[Scheduler] è°ƒåº¦å™¨å¯åŠ¨ï¼Œæ£€æŸ¥é—´éš”: %v", interval)

	for {
		select {
		case <-ctx.Done():
			return
		case <-ticker.C:
			// æ£€æŸ¥æ˜¯å¦åœ¨å·¥ä½œæ—¶é—´æˆ–å¼ºåˆ¶è¿è¡Œ
			if !w.IsWorkingHours() && !w.GetForceRun() {
				continue
			}

			// æ£€æŸ¥æ˜¯å¦æ­£åœ¨ä¼˜é›…å…³é—­
			w.mu.RLock()
			stopped := w.workersStopped
			w.mu.RUnlock()
			if stopped {
				continue // ä¼˜é›…å…³é—­ä¸­ï¼Œä¸å†æ·»åŠ æ–°ä»»åŠ¡
			}

			// æ£€æŸ¥é˜Ÿåˆ—å®¹é‡
			if len(w.taskQueue) >= cap(w.taskQueue) {
				continue // é˜Ÿåˆ—å·²æ»¡ï¼Œè·³è¿‡æœ¬æ¬¡è°ƒåº¦
			}

			// è·å–å¾…å¤„ç†ä»»åŠ¡
			limit := cap(w.taskQueue) - len(w.taskQueue)
			tasks, err := w.db.GetPendingTasks(limit)
			if err != nil {
				log.Printf("[Scheduler] è·å–å¾…å¤„ç†ä»»åŠ¡å¤±è´¥: %v", err)
				continue
			}

			if len(tasks) == 0 {
				continue
			}

			log.Printf("[Scheduler] å‘ç° %d ä¸ªå¾…å¤„ç†ä»»åŠ¡ï¼ŒåŠ å…¥é˜Ÿåˆ—", len(tasks))

			// å°†ä»»åŠ¡åŠ å…¥é˜Ÿåˆ—
			for _, task := range tasks {
				select {
				case w.taskQueue <- task:
					log.Printf("[Scheduler] ä»»åŠ¡ #%d å·²åŠ å…¥é˜Ÿåˆ—: %s", task.ID, task.SourcePath)
				case <-ctx.Done():
					return
				default:
					log.Printf("[Scheduler] é˜Ÿåˆ—å·²æ»¡ï¼Œè·³è¿‡ä»»åŠ¡ #%d", task.ID)
				}
			}
		}
	}
}

// manageWorkerPool åŠ¨æ€ç®¡ç†Worker Poolå¤§å°
func (w *Worker) manageWorkerPool(ctx context.Context) {
	ticker := time.NewTicker(1 * time.Minute)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			return
		case <-ticker.C:
			targetWorkers := w.getTargetWorkerCount()
			currentWorkers := w.GetWorkerCount()

			if targetWorkers != currentWorkers {
				log.Printf("[WorkerPool] è°ƒæ•´Workeræ•°é‡: %d -> %d", currentWorkers, targetWorkers)
				w.adjustWorkerPool(ctx, targetWorkers)
			}
		}
	}
}

// getTargetWorkerCount æ ¹æ®æ—¶é—´çª—å£å’Œå¼ºåˆ¶æ¨¡å¼ç¡®å®šç›®æ ‡Workeræ•°é‡
func (w *Worker) getTargetWorkerCount() int {
	maxWorkers := w.GetMaxWorkers() // ä½¿ç”¨åŠ¨æ€çš„maxWorkers

	if w.GetForceRun() {
		// å¼ºåˆ¶è¿è¡Œï¼šä½¿ç”¨å½“å‰è®¾ç½®çš„æœ€å¤§å¹¶å‘æ•°
		return maxWorkers
	}

	if w.IsWorkingHours() {
		// å·¥ä½œæ—¶é—´ï¼šä½¿ç”¨å½“å‰è®¾ç½®çš„æœ€å¤§å¹¶å‘æ•°
		return maxWorkers
	}

	// éå·¥ä½œæ—¶é—´ï¼šåœæ­¢æ‰€æœ‰Worker
	return 0
}

// adjustWorkerPool è°ƒæ•´Worker Poolå¤§å°
func (w *Worker) adjustWorkerPool(ctx context.Context, targetCount int) {
	w.mu.Lock()
	defer w.mu.Unlock()

	currentCount := w.workerCount

	if currentCount == 0 && targetCount > 0 {
		// å¯åŠ¨Worker Pool
		w.workerCount = targetCount
		w.workersStopped = false

		// åˆ›å»ºæ–°çš„Contextç”¨äºæ§åˆ¶Workers
		w.workerCtx, w.cancelWorkers = context.WithCancel(ctx)

		for i := 0; i < targetCount; i++ {
			w.wg.Add(1)
			go w.processWorker(w.workerCtx, i+1)
		}
		log.Printf("[WorkerPool] å·²å¯åŠ¨ %d ä¸ªWorker", targetCount)

		// æ›´æ–° Prometheus metrics
		metrics.WorkersActive.Set(float64(targetCount))

	} else if currentCount > 0 && targetCount == 0 {
		// ä¼˜é›…åœæ­¢æ‰€æœ‰Workerï¼šä¸å†æ¥å—æ–°ä»»åŠ¡ï¼Œç­‰å¾…å½“å‰ä»»åŠ¡å®Œæˆ
		log.Println("[WorkerPool] è¿›å…¥ä¼˜é›…å…³é—­æ¨¡å¼ï¼Œç­‰å¾…å½“å‰ä»»åŠ¡å®Œæˆ...")

		// è®¾ç½®æ ‡å¿—ï¼šä¸å†æ¥å—æ–°ä»»åŠ¡ï¼ˆè°ƒåº¦å™¨ä¼šæ£€æŸ¥è¿™ä¸ªï¼‰
		w.workersStopped = true

		// å…³é—­ä»»åŠ¡é˜Ÿåˆ—ï¼Œé€šçŸ¥workersä¸å†æœ‰æ–°ä»»åŠ¡
		// ä½†ä¸å–æ¶ˆcontextï¼Œè®©æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡ç»§ç»­å®Œæˆ
		close(w.taskQueue)

		// é‡Šæ”¾é”ï¼Œç­‰å¾…æ‰€æœ‰Workerå®Œæˆå½“å‰ä»»åŠ¡
		w.mu.Unlock()
		log.Println("[WorkerPool] ç­‰å¾…æ‰€æœ‰æ­£åœ¨å¤„ç†çš„ä»»åŠ¡å®Œæˆ...")
		w.wg.Wait()
		log.Println("[WorkerPool] æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆ")
		w.mu.Lock()

		// ç°åœ¨å¯ä»¥å®‰å…¨åœ°æ¸…ç†èµ„æº
		if w.cancelWorkers != nil {
			w.cancelWorkers()
		}

		// é‡æ–°åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—ä¾›ä¸‹æ¬¡å¯åŠ¨ä½¿ç”¨
		w.taskQueue = make(chan *database.Task, w.config.System.TaskQueueSize)

		w.workerCount = 0
		log.Println("[WorkerPool] æ‰€æœ‰Workerå·²ä¼˜é›…åœæ­¢")

		// æ›´æ–° Prometheus metrics
		metrics.WorkersActive.Set(0)

	} else if currentCount > 0 && targetCount > 0 && currentCount != targetCount {
		// åŠ¨æ€è°ƒæ•´Workeræ•°é‡ï¼ˆæš‚ä¸æ”¯æŒï¼Œéœ€é‡å¯ï¼‰
		log.Printf("[WorkerPool] Workeræ•°é‡è°ƒæ•´ %d->%d éœ€é‡å¯Pool", currentCount, targetCount)
	}
}

// processWorker Worker goroutineï¼Œä»é˜Ÿåˆ—ä¸­è·å–ä»»åŠ¡å¹¶å¤„ç†
func (w *Worker) processWorker(ctx context.Context, workerID int) {
	defer w.wg.Done()
	log.Printf("[Worker-%d] å¯åŠ¨", workerID)

	for {
		select {
		case <-ctx.Done():
			log.Printf("[Worker-%d] æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œé€€å‡º", workerID)
			return
		case task, ok := <-w.taskQueue:
			if !ok {
				// é˜Ÿåˆ—å·²å…³é—­ï¼Œè¯´æ˜è¿›å…¥ä¼˜é›…å…³é—­æ¨¡å¼ï¼Œå®Œæˆå½“å‰ä»»åŠ¡åé€€å‡º
				log.Printf("[Worker-%d] ä»»åŠ¡é˜Ÿåˆ—å·²å…³é—­ï¼Œé€€å‡º", workerID)
				return
			}

			log.Printf("[Worker-%d] å¼€å§‹å¤„ç†ä»»åŠ¡ #%d: %s", workerID, task.ID, task.SourcePath)

			// è®°å½•å¼€å§‹æ—¶é—´
			startTime := time.Now()

			// æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
			if err := w.db.UpdateTaskStatus(task.ID, database.StatusProcessing, ""); err != nil {
				log.Printf("[Worker-%d] æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥: %v", workerID, err)
				continue
			}

			// æ‰§è¡Œè½¬ç ï¼ˆä½¿ç”¨ç‹¬ç«‹çš„ contextï¼Œä¸å— ctx.Done() å½±å“ï¼‰
			taskCtx := context.Background()
			if err := w.transcode(taskCtx, task, workerID); err != nil {
				// è¯¦ç»†çš„é”™è¯¯æ—¥å¿—
				errMsg := err.Error()
				log.Printf("[Worker-%d] âŒ è½¬ç å¤±è´¥ #%d: %s", workerID, task.ID, task.SourcePath)

				// åˆ¤æ–­é”™è¯¯ç±»å‹å¹¶ç»™å‡ºæç¤º
				if strings.Contains(errMsg, "æ–‡ä»¶æŸå") || strings.Contains(errMsg, "è§£ç æµ‹è¯•å¤±è´¥") {
					log.Printf("[Worker-%d] ğŸ” æºæ–‡ä»¶æŸåæˆ–æ ¼å¼ä¸æ”¯æŒï¼Œå»ºè®®æ£€æŸ¥: %s", workerID, task.SourcePath)
				} else if strings.Contains(errMsg, "ç£ç›˜ç©ºé—´") {
					log.Printf("[Worker-%d] ğŸ’¾ ç£ç›˜ç©ºé—´ä¸è¶³ï¼Œè½¬ç ä¸­æ­¢", workerID)
				} else if strings.Contains(errMsg, "FFmpegæ‰§è¡Œå¤±è´¥") {
					// æˆªå–å…³é”®é”™è¯¯ä¿¡æ¯ï¼ˆé¿å…æ—¥å¿—è¿‡é•¿ï¼‰
					if len(errMsg) > 1000 {
						log.Printf("[Worker-%d] ğŸ“‹ FFmpegé”™è¯¯ (å‰500å­—ç¬¦): %s", workerID, errMsg[:500])
					} else {
						log.Printf("[Worker-%d] ğŸ“‹ é”™è¯¯è¯¦æƒ…: %s", workerID, errMsg)
					}
				}

				// å¢åŠ é‡è¯•æ¬¡æ•°
				w.db.IncrementRetryCount(task.ID)

				// æ›´æ–°çŠ¶æ€ä¸ºå¤±è´¥ï¼ˆå­˜å‚¨å®Œæ•´é”™è¯¯ä¿¡æ¯åˆ°æ•°æ®åº“ï¼‰
				w.db.UpdateTaskStatus(task.ID, database.StatusFailed, errMsg)

				// æ›´æ–° Prometheus metrics
				metrics.TranscodeFailed.Inc()
			} else {
				log.Printf("[Worker-%d] âœ… è½¬ç æˆåŠŸ #%d: %s", workerID, task.ID, task.SourcePath)

				// æ›´æ–°è¾“å‡ºæ–‡ä»¶å¤§å° - å•æ¬¡éå†è·å–è¾“å‡ºè·¯å¾„
				var outputDir, relPath string
				pairs := w.config.GetPairs()
				for _, pair := range pairs {
					if rel, err := filepath.Rel(pair.Input, task.SourcePath); err == nil && !strings.HasPrefix(rel, "..") {
						outputDir = pair.Output
						relPath = rel
						break
					}
				}

				if outputDir != "" && relPath != "" {
					outputPath := filepath.Join(outputDir, relPath)
					if info, err := os.Stat(outputPath); err == nil {
						w.db.UpdateTaskOutputSize(task.ID, info.Size())

						// è®¡ç®—èŠ‚çœçš„ç©ºé—´
						if task.SourceSize > 0 {
							savedBytes := task.SourceSize - info.Size()
							metrics.SpaceSaved.Add(float64(savedBytes))
						}
					}
				}

				// æ›´æ–°çŠ¶æ€ä¸ºå®Œæˆ
				w.db.UpdateTaskStatus(task.ID, database.StatusCompleted, "è½¬ç æˆåŠŸ")

				// æ›´æ–° Prometheus metrics
				metrics.TranscodeSuccess.Inc()

				// è®°å½•è½¬ç è€—æ—¶
				duration := time.Since(startTime).Seconds()
				metrics.TranscodeDuration.Observe(duration)
			}
		}
	}
}

// transcode æ‰§è¡ŒFFmpegè½¬ç 
func (w *Worker) transcode(ctx context.Context, task *database.Task, workerID int) error {
	// æºæ–‡ä»¶çš„å®Œæ•´è·¯å¾„å°±æ˜¯task.SourcePath
	inputPath := task.SourcePath

	// å•æ¬¡éå†æ‰¾åˆ°åŒ¹é…çš„è¾“å…¥ç›®å½•ï¼ŒåŒæ—¶è·å–è¾“å‡ºç›®å½•å’Œç›¸å¯¹è·¯å¾„
	var (
		outputDir string
		relPath   string
	)
	pairs := w.config.GetPairs()
	for _, pair := range pairs {
		if rel, err := filepath.Rel(pair.Input, inputPath); err == nil && !strings.HasPrefix(rel, "..") {
			outputDir = pair.Output
			relPath = rel
			break
		}
	}

	if outputDir == "" || relPath == "" {
		return fmt.Errorf("æ— æ³•æ‰¾åˆ°æºæ–‡ä»¶å¯¹åº”çš„è¾“å…¥è¾“å‡ºé…å¯¹: %s", inputPath)
	}

	// æ„å»ºè¾“å‡ºè·¯å¾„ï¼ˆä¿æŒç›®å½•ç»“æ„ï¼‰
	outputPath := filepath.Join(outputDir, relPath)

	// ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
	outputPathDir := filepath.Dir(outputPath)
	if err := os.MkdirAll(outputPathDir, 0755); err != nil {
		return fmt.Errorf("åˆ›å»ºè¾“å‡ºç›®å½•å¤±è´¥: %w", err)
	}

	// æ£€æŸ¥ç£ç›˜ç©ºé—´
	if err := w.checkDiskSpace(outputPathDir); err != nil {
		return fmt.Errorf("ç£ç›˜ç©ºé—´æ£€æŸ¥å¤±è´¥: %w", err)
	}

	// ä½¿ç”¨ffprobeæ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§
	if err := w.probeFile(inputPath); err != nil {
		return fmt.Errorf("æ–‡ä»¶æ£€æŸ¥å¤±è´¥: %w", err)
	}

	// è·å–è§†é¢‘æ€»æ—¶é•¿
	duration, err := w.getDuration(inputPath)
	if err != nil {
		log.Printf("[Worker-%d] è·å–è§†é¢‘æ—¶é•¿å¤±è´¥: %v", workerID, err)
		duration = 0
	}

	// æ„å»ºFFmpegå‘½ä»¤
	args := []string{
		"-y",                  // è¦†ç›–è¾“å‡ºæ–‡ä»¶
		"-progress", "pipe:1", // è¾“å‡ºè¿›åº¦åˆ°stdout
		"-i", inputPath, // è¾“å…¥æ–‡ä»¶
		"-c:v", w.config.FFmpeg.Codec, // è§†é¢‘ç¼–ç å™¨
		"-preset", w.config.FFmpeg.Preset, // é¢„è®¾
		"-crf", strconv.Itoa(w.config.FFmpeg.CRF), // CRFè´¨é‡
		"-c:a", w.config.FFmpeg.Audio, // éŸ³é¢‘ç¼–ç å™¨
		"-b:a", w.config.FFmpeg.AudioBitrate, // éŸ³é¢‘æ¯”ç‰¹ç‡
		"-movflags", "+faststart", // ä¼˜åŒ–æµå¼æ’­æ”¾
		outputPath, // è¾“å‡ºæ–‡ä»¶
	}

	cmd := exec.CommandContext(ctx, "ffmpeg", args...)

	// è·å–stdoutå’Œstderr
	stdout, err := cmd.StdoutPipe()
	if err != nil {
		return fmt.Errorf("åˆ›å»ºstdoutç®¡é“å¤±è´¥: %w", err)
	}

	stderr, err := cmd.StderrPipe()
	if err != nil {
		return fmt.Errorf("åˆ›å»ºstderrç®¡é“å¤±è´¥: %w", err)
	}

	// å¯åŠ¨å‘½ä»¤
	if err := cmd.Start(); err != nil {
		return fmt.Errorf("å¯åŠ¨FFmpegå¤±è´¥: %w", err)
	}

	// æ”¶é›†stderræ—¥å¿—
	var stderrBuf strings.Builder
	go func() {
		scanner := bufio.NewScanner(stderr)
		for scanner.Scan() {
			stderrBuf.WriteString(scanner.Text() + "\n")
		}
	}()

	// è§£æè¿›åº¦
	go w.parseProgress(bufio.NewReader(stdout), task.ID, duration, workerID)

	// ç­‰å¾…å‘½ä»¤å®Œæˆ
	if err := cmd.Wait(); err != nil {
		return fmt.Errorf("FFmpegæ‰§è¡Œå¤±è´¥: %w\næ—¥å¿—:\n%s", err, stderrBuf.String())
	}

	return nil
}

// probeFile ä½¿ç”¨ffprobeæ£€æŸ¥æ–‡ä»¶
func (w *Worker) probeFile(path string) error {
	// å¢å¼ºæ£€æŸ¥ï¼šåŒæ—¶éªŒè¯è§†é¢‘æµå’ŒéŸ³é¢‘æµ
	cmd := exec.Command("ffprobe",
		"-v", "error",
		"-select_streams", "v:0", // æ£€æŸ¥ç¬¬ä¸€ä¸ªè§†é¢‘æµ
		"-show_entries", "stream=codec_name,duration",
		"-of", "default=noprint_wrappers=1",
		path,
	)

	output, err := cmd.CombinedOutput()
	if err != nil {
		return fmt.Errorf("è§†é¢‘æµæ£€æŸ¥å¤±è´¥ (æ–‡ä»¶å¯èƒ½æŸå): %w, output: %s", err, string(output))
	}

	// æ£€æŸ¥è¾“å‡ºæ˜¯å¦ä¸ºç©º
	if len(output) == 0 {
		return fmt.Errorf("æ— æ³•æ£€æµ‹åˆ°æœ‰æ•ˆçš„è§†é¢‘æµ")
	}

	// é¢å¤–æ£€æŸ¥ï¼šå°è¯•è§£ç å‰å‡ å¸§
	decodeCmd := exec.Command("ffmpeg",
		"-v", "error",
		"-t", "2", // åªæ£€æŸ¥å‰2ç§’
		"-i", path,
		"-f", "null",
		"-",
	)

	decodeOutput, decodeErr := decodeCmd.CombinedOutput()
	if decodeErr != nil {
		// æ£€æŸ¥æ˜¯å¦æœ‰è§£ç é”™è¯¯
		errMsg := string(decodeOutput)
		if strings.Contains(errMsg, "Invalid") || strings.Contains(errMsg, "Error") {
			return fmt.Errorf("æ–‡ä»¶è§£ç æµ‹è¯•å¤±è´¥ (æ–‡ä»¶æŸåæˆ–æ ¼å¼ä¸æ”¯æŒ): %s", errMsg[:min(500, len(errMsg))])
		}
	}

	return nil
}

func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}

// getDuration è·å–è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
func (w *Worker) getDuration(path string) (float64, error) {
	cmd := exec.Command("ffprobe",
		"-v", "error",
		"-show_entries", "format=duration",
		"-of", "default=noprint_wrappers=1:nokey=1",
		path,
	)

	output, err := cmd.CombinedOutput()
	if err != nil {
		return 0, err
	}

	durationStr := strings.TrimSpace(string(output))
	duration, err := strconv.ParseFloat(durationStr, 64)
	if err != nil {
		return 0, err
	}

	return duration, nil
}

// parseProgress è§£æFFmpegè¿›åº¦è¾“å‡º (ä¼˜åŒ–ï¼šæ¯5%æˆ–5ç§’æ›´æ–°ä¸€æ¬¡)
func (w *Worker) parseProgress(reader *bufio.Reader, taskID int64, totalDuration float64, workerID int) {
	scanner := bufio.NewScanner(reader)
	lastUpdate := time.Now()
	lastProgress := 0.0

	for scanner.Scan() {
		line := scanner.Text()

		// è§£æ out_time_ms
		if strings.HasPrefix(line, "out_time_ms=") {
			parts := strings.SplitN(line, "=", 2)
			if len(parts) != 2 {
				continue
			}

			outTimeMs, err := strconv.ParseInt(parts[1], 10, 64)
			if err != nil {
				continue
			}

			if totalDuration > 0 {
				// è®¡ç®—ç™¾åˆ†æ¯”
				outTimeSeconds := float64(outTimeMs) / 1000000.0
				progress := (outTimeSeconds / totalDuration) * 100.0

				// é™åˆ¶åœ¨0-100ä¹‹é—´
				if progress < 0 {
					progress = 0
				} else if progress > 100 {
					progress = 100
				}

				// ä¼˜åŒ–ï¼šæ¯5%æˆ–æ¯5ç§’æ›´æ–°ä¸€æ¬¡æ•°æ®åº“
				progressDelta := progress - lastProgress
				timeSinceLastUpdate := time.Since(lastUpdate)

				if progressDelta >= 5.0 || timeSinceLastUpdate >= 5*time.Second {
					w.db.UpdateTaskProgress(taskID, progress)
					lastUpdate = time.Now()
					lastProgress = progress
					log.Printf("[Worker-%d] ä»»åŠ¡ #%d è¿›åº¦: %.1f%%", workerID, taskID, progress)
				}
			}
		}
	}

	// æœ€åç¡®ä¿è¿›åº¦è®¾ä¸º100%
	if totalDuration > 0 {
		w.db.UpdateTaskProgress(taskID, 100.0)
		log.Printf("[Worker-%d] ä»»åŠ¡ #%d å·²å®Œæˆ", workerID, taskID)
	}
}

// checkDiskSpace æ£€æŸ¥ç£ç›˜ç©ºé—´
func (w *Worker) checkDiskSpace(path string) error {
	var stat syscall.Statfs_t
	if err := syscall.Statfs(path, &stat); err != nil {
		return fmt.Errorf("è·å–ç£ç›˜ä¿¡æ¯å¤±è´¥: %w", err)
	}

	// è®¡ç®—å¯ç”¨ç©ºé—´ï¼ˆGBï¼‰
	availableGB := float64(stat.Bavail*uint64(stat.Bsize)) / 1024 / 1024 / 1024
	minRequiredGB := float64(w.config.System.MinDiskSpaceGB)

	if availableGB < minRequiredGB {
		return fmt.Errorf("ç£ç›˜ç©ºé—´ä¸è¶³: å¯ç”¨ %.2fGB, éœ€è¦è‡³å°‘ %.0fGB", availableGB, minRequiredGB)
	}

	log.Printf("[Worker] ç£ç›˜å¯ç”¨ç©ºé—´: %.2fGB", availableGB)
	return nil
}
